# ğŸ¯ Backend for Emotion Detection Using Audio-Visual Modalities

This Node.js backend powers a React-based frontend for detecting human emotions from both audio and video inputs. Designed with safety-critical environments in mindâ€”like driver monitoring systemsâ€”this backend processes inputs, runs AI inference, and returns predicted emotional states.

---

## ğŸ“Œ Overview

This backend is part of a full-stack application that enables real-time emotion detection using multimodal data (audio + visual). It uses pre-trained and fine-tuned deep learning models to analyze audio features (like MFCCs) and video frames to infer emotions such as happiness, anger, fear, etc.

---

## ğŸ§  AI Model Details

- **Model Name**: VideoMAE (Masked Autoencoder for Video)
- **Fine-tuned Version**: `TFVideoMAE_L_K400_16x224_FT`
- **Pre-trained on**: Kinetics-400
- **Frameworks Used**: TensorFlow, Keras
- **Inference Mode**: Python (served via Node.js)

---

## ğŸ“‚ Datasets Used

- ğŸ§ **CREMA-D**  
  - Includes 7442 labeled audio-visual clips  
  - Labels: Angry, Happy, Neutral, Disgust, Fear, Sad

- ğŸ¥ **eNTERFACE**
  - Multimodal emotion dataset with video and audio clips  
  - Ideal for validating cross-dataset generalization

---

## ğŸ”§ Data Preprocessing and Fusion

### ğŸ™ï¸ Audio Processing

- **MFCCs** (Mel-Frequency Cepstral Coefficients)
- **Mel Spectrograms**
- Converted to image format for CNN-based feature extraction

### ğŸï¸ Video Processing

- Video split into fixed-length clips (e.g., 2 seconds)
- Frames extracted at 16 FPS and resized to `224x224`

### ğŸ”— Fusion Techniques

1. **Early Fusion**:  
   Audio and video features combined before classification.

2. **Late Fusion**:  
   Separate branches for audio and video â†’ merged at decision layer.

---

## ğŸŒ API Endpoints

| Endpoint              | Method | Description                          |
|-----------------------|--------|--------------------------------------|
| `/upload/audio`       | POST   | Uploads audio file for processing    |
| `/upload/video`       | POST   | Uploads video file for processing    |
| `/predict`            | POST   | Runs inference and returns emotion   |

---

## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/backend-emotion-detection.git
cd backend-emotion-detection
